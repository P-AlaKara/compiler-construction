# COMPILER CONSTRUCTION
Attempt at a simple C compiler 


---
# Lexical Analysis Phase 

The operation of **Flex**, a powerful lexical analyzer generator, is explained, followed by an in-depth analysis of the lexer's structure and token recognition rules.

---

## Understanding Flex and Lexical Analysis

**Flex** (Fast Lexical Analyzer Generator) is a tool that generates programs (lexical analyzers or "scanners") that perform pattern-matching on text. A specification file (such as the `lexer.l` file) containing regular expressions and corresponding actions is processed by Flex to generate a C source file (typically `lex.yy.c`). This generated C file contains the `yylex()` function, which is the core of the lexical analyzer.

The primary role of the lexical analyzer (lexer) in a compiler is to read the raw source code character by character and group them into a stream of meaningful units called **tokens**. These tokens are then passed to the parser (generated by Bison).

A simplified overview of Flex's operation within a typical compiler workflow is presented below:

1.  **Input Reading:** The lexer reads characters from the input stream (usually a source code file).
2.  **Pattern Matching:** It attempts to match sequences of characters against the regular expressions (patterns) defined in the `lexer.l` file.
3.  **Token Generation:** When a pattern is successfully matched, the associated C code action is executed. This action typically constructs a **token** and returns it to the parser. A token usually consists of a `token_type` (an enumerated value representing the category of the token, like `IDENTIFIER` or `PLUS`) and a `semantic_value` (additional data associated with the token, like the actual name of an identifier or the value of a constant).
4.  **Skipping Irrelevant Characters:** Characters that are not part of any meaningful token (e.g., whitespace, comments) are skipped by the lexer.
5.  **Error Reporting:** If a sequence of characters does not match any defined pattern, a lexical error is reported.

---

## Structure of `lexer.l`

A Flex specification file (`.l` or `.lex`) is typically divided into three main sections, separated by `%%`:

```c
%{ /* C Declarations and Definitions */ %}
/* Flex Definitions (Options and Macros) */
%%
/* Regular Expression Rules and Actions */
%%
/* Additional C Code (e.g., main function, helper functions) */
```

Each section of the `lexer.l` file is detailed below:

### C Declarations and Definitions Section (`%{ ... %}`)

```c
%{
#include "parser.tab.h" // Include the header file Bison will generate
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>


// Declare yyin - input file pointer, used by Lex/Flex.
extern FILE *yyin;

// **REQUIRED:** Declare yylineno - managed by Lex/Flex when %option yylineno is used
extern int yylineno; // <-- Declare yylineno here

/* Remove 'int current_line = 1;' */
/* Remove '// extern int yylineno;' */

%}
```

This section, enclosed within `%{` and `%}`, contains C code that is directly copied into the generated `lex.yy.c` file. This is where necessary header files are included, global variables are declared, and any helper functions used by the actions are defined.

* `#include "parser.tab.h"`: This is a crucial include. When Bison generates its parser (`parser.tab.c`), it also generates a header file (`parser.tab.h`) that defines the token types (e.g., `IF`, `IDENTIFIER`, `CONSTANT`) as integer constants. The lexer needs these definitions to return the correct token types to the parser.
* `#include <stdio.h>`, `#include <stdlib.h>`, `#include <string.h>`, `#include <ctype.h>`: These are standard C library includes that provide functions for input/output, general utilities (like memory allocation with `strdup` and `atoi`), string manipulation, and character type checking, respectively.
* `extern FILE *yyin;`: `yyin` is an external `FILE*` pointer used by Flex to read input. It is typically set in the `main` function to point to the source code file being compiled.
* `extern int yylineno;`: `yylineno` is an external integer variable that stores the current line number being processed by the lexer. Flex automatically manages and updates this variable when the `%option yylineno` is used in the definitions section. This is extremely useful for reporting errors with precise line numbers.

---

### Flex Definitions Section

```c
/* Definitions section */

%option noyywrap
%option yylineno
```

This section contains directives that configure Flex's behavior.

* `%option noyywrap`: This option tells Flex not to call `yywrap()` when it reaches the end of the input file. By default, Flex tries to call `yywrap()` to see if there are more input files to process. For a simple single-file compilation, this behavior is not needed.
* `%option yylineno`: This option instructs Flex to automatically maintain the `yylineno` variable, incrementing it every time a newline character (`\n`) is encountered in the input. This eliminates the need for manual line counting within the lexer actions.

---

### Regular Expression Rules and Actions Section (`%% ... %%`)

```c
%% /* Rules section */

"if" { return IF; }
"else" { return ELSE; }
"print" { return PRINT; }
"int" {return INT_KEYWORD; }
"bool" { return BOOL_KEYWORD; }
"true" { yylval.ival = 1; return BOOLEAN_LITERAL; }
"false" { yylval.ival = 0; return BOOLEAN_LITERAL; }

"=="|"!="|"<="|">="|"<"|">" { yylval.sval = strdup(yytext); return COMPARISON_OPERATOR; }
"=" { yylval.sval = strdup(yytext); return ASSIGNMENT_OPERATOR; }

"+" { yylval.sval = strdup(yytext); return PLUS; }
"-" { yylval.sval = strdup(yytext); return MINUS; }
"*" { yylval.sval = strdup(yytext); return TIMES; }
"/" { yylval.sval = strdup(yytext); return DIVIDE; }

"(" { return LEFT_PAREN; }
")" { return RIGHT_PAREN; }
"{" { return LEFT_BRACE; }
"}" { return RIGHT_BRACE; }
";" { return SEMICOLON; }

[0-9]+ { yylval.ival = atoi(yytext); return CONSTANT; }
[a-zAZ_][a-zA-Z0-9_]* { yylval.sval = strdup(yytext); return IDENTIFIER; }

"//".* { /* Skip comment */ }
[ \t]+ { /* Skip spaces and tabs */ }
\n { /* Lex automatically updates yylineno because of %option yylineno */ }

. {fprintf(stderr, "Lexical Error: Unknown character '%s' at line %d\n", yytext, yylineno);
  exit(1);
}
```

This is the core of the lexer, where regular expressions are defined to match patterns in the input text, and corresponding C actions are specified to be executed when a match occurs. Flex matches the longest possible pattern from the beginning of the input. If multiple patterns match the same longest prefix, the one appearing first in the `lexer.l` file takes precedence.

* **`yytext`**: This is a global character array (or pointer) automatically provided by Flex. It holds the text of the currently matched token.
* **`yylval`**: This is a global union (defined in `parser.tab.h` by Bison's `%union` directive) used to pass semantic values from the lexer to the parser. The appropriate member of the union (`ival` for integers, `sval` for strings, `node` for AST nodes) is set based on the token type.
* **`return TOKEN_TYPE;`**: When a token is recognized, its corresponding integer value (defined in `parser.tab.h`) is returned to the parser.

Let's break down each rule:

* **Keywords:**
    * `"if" { return IF; }`
    * `"else" { return ELSE; }`
    * `"print" { return PRINT; }`
    * `"int" {return INT_KEYWORD; }`
    * `"bool" { return BOOL_KEYWORD; }`
        * These rules match exact string literals representing keywords. When matched, the corresponding token type (e.g., `IF`, `ELSE`) is returned. These are typically defined as unique integer values in `parser.tab.h`.

* **Boolean Literals:**
    * `"true" { yylval.ival = 1; return BOOLEAN_LITERAL; }`
    * `"false" { yylval.ival = 0; return BOOLEAN_LITERAL; }`
        * These match the boolean keywords. The `yylval.ival` member of the semantic value union is set to `1` for `true` and `0` for `false`, and `BOOLEAN_LITERAL` is returned.

* **Operators:**
    * `"=="|"!="|"<="|">="|"<"|">" { yylval.sval = strdup(yytext); return COMPARISON_OPERATOR; }`
        * This rule uses the `|` (OR) operator to match any of the listed comparison operators. `yytext` contains the matched operator (e.g., "=="). `strdup(yytext)` creates a duplicate of this string in dynamically allocated memory, and its pointer is assigned to `yylval.sval`. This is crucial because `yytext`'s content can change on the next token match. `COMPARISON_OPERATOR` is returned.
    * `"=" { yylval.sval = strdup(yytext); return ASSIGNMENT_OPERATOR; }`
        * Matches the assignment operator. Similar to comparison operators, its string representation is duplicated and returned.
    * `"+" { yylval.sval = strdup(yytext); return PLUS; }`
    * `"-" { yylval.sval = strdup(yytext); return MINUS; }`
    * `"*" { yylval.sval = strdup(yytext); return TIMES; }`
    * `"/" { yylval.sval = strdup(yytext); return DIVIDE; }`
        * These rules match the arithmetic operators. Their string representation is duplicated and returned.

* **Punctuation:**
    * `"(" { return LEFT_PAREN; }`
    * `)` { return RIGHT_PAREN; }`
    * `"{" { return LEFT_BRACE; }`
    * `"}" { return RIGHT_BRACE; }`
    * `;` { return SEMICOLON; }`
        * These rules match various punctuation characters and return their corresponding token types. No semantic value is typically needed for these.

* **Literals and Identifiers:**
    * `[0-9]+ { yylval.ival = atoi(yytext); return CONSTANT; }`
        * Matches one or more digits (`[0-9]+`). `atoi(yytext)` converts the matched string (e.g., "123") into an integer, which is stored in `yylval.ival`. `CONSTANT` is returned.
    * `[a-zA-Z_][a-zA-Z0-9_]* { yylval.sval = strdup(yytext); return IDENTIFIER; }`
        * Matches a valid identifier: starts with a letter or underscore (`[a-zA-Z_]`), followed by zero or more letters, digits, or underscores (`[a-zA-Z0-9_]*`). The matched identifier string is duplicated using `strdup()` and stored in `yylval.sval`. `IDENTIFIER` is returned. This rule's position after keyword rules is important; if it were before, keywords like "if" would be incorrectly identified as identifiers. Flex's "longest match, then first rule" behavior ensures keywords are prioritized.

* **Whitespace and Comments (Skipping Rules):**
    * `"//".* { /* Skip comment */ }`
        * Matches a single-line comment: two forward slashes (`//`) followed by any characters (`.`) zero or more times (`*`) until the end of the line. The action is empty (`/* Skip comment */`), meaning these characters are consumed and nothing is returned to the parser.
    * `[ \t]+ { /* Skip spaces and tabs */ }`
        * Matches one or more spaces or tabs. Again, the action is empty, effectively skipping these whitespace characters.
    * `\n { /* Lex automatically updates yylineno because of %option yylineno */ }`
        * Matches a newline character. The action is empty, but importantly, due to the `%option yylineno` directive, Flex automatically increments `yylineno` here.

* **Error Handling:**
    * `. {fprintf(stderr, "Lexical Error: Unknown character '%s' at line %d\n", yytext, yylineno); exit(1);}`
        * This is the **catch-all rule**. The `.` (dot) regular expression matches any single character except a newline. This rule is placed last to ensure it only matches characters that none of the previous, more specific rules have matched.
        * **Action**: If an unknown character is encountered, an error message is printed to `stderr` using `fprintf`, including the offending character (`yytext`) and the current line number (`yylineno`). The program then terminates using `exit(1)`. This is a robust way to handle unexpected input.

---


# Parsing Phase Documentation

This documentation details the parsing phase of the compiler project, focusing on the provided `parser.y` file. The operation of **Bison**, a powerful parser generator, is explained, followed by an in-depth analysis of the parser's structure and functions.

---

## Understanding Bison and Parser Generation

**Bison** (GNU Parser Generator) converts a **context-free grammar** description into a C, C++, or Java program capable of parsing that grammar. A grammar specification (such as the `parser.y` file) is processed by Bison to generate a C source file (typically `parser.tab.c`), which contains the `yyparse()` function. This `yyparse()` function serves as the core of the parser.

A simplified overview of Bison's operation within a typical compiler workflow is presented below:

1.  **Lexical Analysis (Scanning):** Prior to parsing, the raw source code is broken down into a stream of meaningful units called **tokens**. This task is handled by a **lexer** (often generated by **Flex**, a lexical analyzer generator). The lexer reads the input character by character and produces tokens (e.g., `IDENTIFIER`, `CONSTANT`, `PLUS`, `SEMICOLON`).
2.  **Syntactic Analysis (Parsing):** The `yyparse()` function, generated by Bison, takes this stream of tokens from the lexer (`yylex()`) and attempts to construct a **parse tree** (or more commonly, an **Abstract Syntax Tree - AST**) based on the defined grammar rules. This process verifies if the sequence of tokens conforms to the language's syntax.
3.  **Semantic Actions:** As grammar rules are recognized by the parser, **semantic actions** (C code blocks) embedded within the `parser.y` file are executed. These actions are performed whenever a rule is successfully matched. In this context, these semantic actions are responsible for constructing the **Abstract Syntax Tree (AST)**, which is a tree representation of the program's structure.
4.  **Error Handling:** If the parser encounters a sequence of tokens that does not conform to the grammar, a **syntax error** is reported. The handling of these errors is defined, as is done with `yyerror()`.

Bison employs an **LALR(1)** parsing algorithm, which is a type of bottom-up parser. This means the parse tree is constructed from the leaves (tokens) up to the root (the start symbol of the grammar). The "(1)" in LALR(1) indicates that one token is looked ahead to make parsing decisions.

---

## Structure of `parser.y`

A Bison grammar file (`.y` or `.yy`) is typically divided into three main sections, separated by `%%`:

```c
%{ /* C Declarations and Definitions */ %}
/* Bison Declarations */
%%
/* Grammar Rules */
%%
/* Additional C Code */
```

Each section of the `parser.y` file is detailed below:

### C Declarations and Definitions Section (`%{ ... %}`)

```c
%{
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include "ast.h"
#include "semantic.h"
#include "codegen.h"
ASTNode* root = NULL;
int yylex(void);
void yyerror(const char *s);
extern FILE *yyin;
extern int yylineno;
extern int print_tokens; // Add reference to print_tokens flag
int syntax_errors = 0;  // Add a counter for syntax errors
%}
```

This section, enclosed within `%{` and `%}`, contains C code that is directly copied into the generated `parser.tab.c` file. Global variables are declared, necessary header files are included, and any helper functions required by semantic actions or the parser itself are defined here.

* `#include <stdio.h>`, `#include <stdlib.h>`, `#include <string.h>`: These are standard C library includes that provide functions for input/output, general utilities (such as memory allocation), and string manipulation, respectively.
* `#include "ast.h"`, `#include "semantic.h"`, `#include "codegen.h"`: These lines include custom header files for other compiler phases:
    * `ast.h`: This file likely defines the structures and functions for building and manipulating the **Abstract Syntax Tree (AST)**.
    * `semantic.h`: This file contains declarations for functions related to **semantic analysis** (e.g., type checking, symbol table management).
    * `codegen.h`: This file contains declarations for functions responsible for **code generation** (e.g., generating intermediate code or assembly).
* `ASTNode* root = NULL;`: A global pointer `root` of type `ASTNode*` is declared and initialized to `NULL`. This pointer eventually holds the root of the entire Abstract Syntax Tree, representing the parsed program.
* `int yylex(void);`: This declares the **lexer function**. A function named `yylex()` is expected by Bison to provide the next token from the input. This function is typically generated by Flex.
* `void yyerror(const char *s);`: This declares the **error reporting function**. When a syntax error is encountered by Bison, `yyerror()` is called with an error message string. An implementation of this function is provided later in the file.
* `extern FILE *yyin;`: `yyin` is declared as an external `FILE*` pointer. This is the input stream from which the lexer (`yylex()`) reads. It is typically set by the `main` function.
* `extern int yylineno;`: `yylineno` is declared as an external integer. This variable, usually maintained by the lexer, stores the current line number in the input file, which is useful for error reporting.
* `extern int print_tokens;`: An external integer `print_tokens` is declared. This flag is likely used to control whether tokens are printed during lexical analysis, as observed in the `main` function.
* `int syntax_errors = 0;`: A global integer `syntax_errors` is declared and initialized. This variable functions as a counter to track the number of syntax errors encountered during parsing.

---

### Bison Declarations Section

```c
%union {
    char* sval;
    int ival;
    struct ASTNode* node;
}

%token <sval> IDENTIFIER COMPARISON_OPERATOR ASSIGNMENT_OPERATOR
%token <sval> PLUS MINUS TIMES DIVIDE
%token IF ELSE PRINT INT_KEYWORD
%token <ival> BOOLEAN_LITERAL
%token BOOL_KEYWORD
%token LEFT_PAREN RIGHT_PAREN LEFT_BRACE RIGHT_BRACE SEMICOLON
%token <ival> CONSTANT
%type <node> program statement_list statement declaration assignment comparison expression
%start program

%left PLUS MINUS
%left TIMES DIVIDE
```

This section contains declarations specific to Bison, defining the types of values associated with tokens and non-terminal symbols, as well as operator precedence and associativity.

* `%union { ... }`: This declares the **union type** that Bison uses for the semantic values associated with tokens and non-terminals. Each grammar rule has an associated value, accessible via `$$`. The values of components of the rule are accessed via `$1`, `$2`, etc.
    * `sval`: Used for string values (e.g., identifiers, operators).
    * `ival`: Used for integer values (e.g., constants, boolean literals).
    * `node`: Used for pointers to `ASTNode` structures, which is crucial for AST construction.
* `%token <type> TOKEN_NAME`: These lines declare the **terminal symbols** (tokens) that are produced by the lexer. The `<type>` specifies which member of the `%union` should be used to store the semantic value of that token.
    * `%token <sval> IDENTIFIER COMPARISON_OPERATOR ASSIGNMENT_OPERATOR`: Tokens like `IDENTIFIER`, `==`, `=`, etc., have string values.
    * `%token <sval> PLUS MINUS TIMES DIVIDE`: Arithmetic operators.
    * `%token IF ELSE PRINT INT_KEYWORD`: Keywords.
    * `%token <ival> BOOLEAN_LITERAL`: Boolean literals (true/false) have integer values (likely 0 or 1).
    * `%token BOOL_KEYWORD`: The boolean keyword.
    * `%token LEFT_PAREN RIGHT_PAREN LEFT_BRACE RIGHT_BRACE SEMICOLON`: Punctuation symbols.
    * `%token <ival> CONSTANT`: Integer constants have integer values.
* `%type <node> NON_TERMINAL_NAME`: These lines declare the **non-terminal symbols** (grammar rules) and specify which member of the `%union` should be used to store their semantic value. In this case, almost all non-terminals (`program`, `statement_list`, `statement`, `declaration`, `assignment`, `comparison`, `expression`) produce an `ASTNode*` pointer, indicating their contribution to the AST.
* `%start program`: This specifies `program` as the **start symbol** of the grammar. Parsing begins with this rule.
* `%left PLUS MINUS` and `%left TIMES DIVIDE`: These lines define the **precedence** and **associativity** of operators.
    * `%left` indicates **left associativity** (e.g., `a - b - c` is parsed as `(a - b) - c`).
    * Rules appearing later have higher precedence. Thus, `TIMES` and `DIVIDE` have higher precedence than `PLUS` and `MINUS`, following standard arithmetic rules. This resolves ambiguities in expressions like `a + b * c` (parsed as `a + (b * c)`).

---

### Grammar Rules Section (`%% ... %%`)

```c
%%
program:
    statement_list          { extern ASTNode* root;
        root = $1; }
;

statement_list:
      /* empty */             { $$ = make_stmt_list_node(); }
    | statement_list statement  { add_statement($1, $2); $$ = $1; }
;

statement:
      declaration SEMICOLON         { $$ = $1; }
    | assignment SEMICOLON          { $$ = $1; }
    | PRINT expression SEMICOLON    { $$ = make_print_node($2); }
    | IF LEFT_PAREN comparison RIGHT_PAREN LEFT_BRACE statement_list RIGHT_BRACE ELSE LEFT_BRACE statement_list RIGHT_BRACE
                                    { $$ = make_if_node($3, $6, $10); }
    | IF LEFT_PAREN comparison RIGHT_PAREN LEFT_BRACE statement_list RIGHT_BRACE
                                    { $$ = make_if_node($3, $6, NULL); }
;

declaration:
    INT_KEYWORD IDENTIFIER          { $$ = make_declaration_node($2, NULL, TYPE_INT); }
    | INT_KEYWORD IDENTIFIER ASSIGNMENT_OPERATOR expression  { $$ = make_declaration_node($2, $4, TYPE_INT); }
    | BOOL_KEYWORD IDENTIFIER { $$ = make_declaration_node($2, NULL, TYPE_BOOL); }
    | BOOL_KEYWORD IDENTIFIER ASSIGNMENT_OPERATOR expression  { $$ = make_declaration_node($2, $4, TYPE_BOOL); }
;

assignment:
    IDENTIFIER ASSIGNMENT_OPERATOR expression
                                    { $$ = make_assign_node($1, $3); }
;

comparison:
    expression COMPARISON_OPERATOR expression
                                    { $$ = make_binop_node($2, $1, $3); }
;

expression:
      CONSTANT                      { $$ = make_int_node($1); }
    | BOOLEAN_LITERAL               { $$ = make_bool_node($1); }
    | IDENTIFIER                    { $$ = make_var_node($1); }
    | expression PLUS expression    { $$ = make_binop_node("+", $1, $3); }
    | expression MINUS expression   { $$ = make_binop_node("-", $1, $3); }
    | expression TIMES expression   { $$ = make_binop_node("*", $1, $3); }
    | expression DIVIDE expression  { $$ = make_binop_node("/", $1, $3); }
    | LEFT_PAREN expression RIGHT_PAREN
                                    { $$ = $2; }
;
```

This section constitutes the core of the grammar, defining the syntax of the programming language using **Backus-Naur Form (BNF)**-like rules. Each rule has a left-hand side (a non-terminal) and a right-hand side (a sequence of terminals and/or non-terminals), followed by a C code block known as a **semantic action**.

* `$$`: Represents the semantic value of the non-terminal on the left-hand side of the rule.
* `$1, $2, ...`: Represent the semantic values of the symbols on the right-hand side of the rule, from left to right.

Each rule is examined below:

* **`program`**:
    * `program: statement_list { extern ASTNode* root; root = $1; };`
        * A `program` is simply a `statement_list`.
        * **Semantic Action**: Once a `statement_list` is successfully parsed, its semantic value (`$1`, which is an `ASTNode*` representing the list of statements) is assigned to the global `root` variable. This establishes the entry point for the AST.

* **`statement_list`**:
    * `statement_list: /* empty */ { $$ = make_stmt_list_node(); }`
        * An empty `statement_list` is considered valid (e.g., an empty program block).
        * **Semantic Action**: If empty, an empty statement list node is created using `make_stmt_list_node()`.
    * `| statement_list statement { add_statement($1, $2); $$ = $1; }`
        * A `statement_list` can be recursively defined as an existing `statement_list` followed by a `statement`. This allows for sequences of statements.
        * **Semantic Action**: The newly parsed `statement` (`$2`) is added to the existing `statement_list` (`$1`) via `add_statement($1, $2)`. The result (`$$`) is the updated `statement_list` (`$1`).

* **`statement`**: This rule defines the different types of statements allowed in the language.
    * `declaration SEMICOLON { $$ = $1; }`: A declaration followed by a semicolon. The semantic value is simply the AST node for the declaration.
    * `assignment SEMICOLON { $$ = $1; }`: An assignment followed by a semicolon. The semantic value is the AST node for the assignment.
    * `PRINT expression SEMICOLON { $$ = make_print_node($2); }`: A `PRINT` keyword followed by an `expression` and a semicolon.
        * **Semantic Action**: A print statement AST node is created by `make_print_node($2)`, taking the AST node for the `expression` (`$2`) as its argument.
    * `IF LEFT_PAREN comparison RIGHT_PAREN LEFT_BRACE statement_list RIGHT_BRACE ELSE LEFT_BRACE statement_list RIGHT_BRACE { $$ = make_if_node($3, $6, $10); }`: An `if-else` statement.
        * **Semantic Action**: An `if` statement AST node is created by `make_if_node($3, $6, $10)`, taking the comparison (`$3`), the "then" block's statement list (`$6`), and the "else" block's statement list (`$10`) as arguments.
    * `IF LEFT_PAREN comparison RIGHT_PAREN LEFT_BRACE statement_list RIGHT_BRACE { $$ = make_if_node($3, $6, NULL); }`: An `if` statement without an `else` block.
        * **Semantic Action**: Similar to the `if-else` rule, but `NULL` is passed for the `else` block.

* **`declaration`**: Defines how variables are declared.
    * `INT_KEYWORD IDENTIFIER { $$ = make_declaration_node($2, NULL, TYPE_INT); }`: Integer declaration without initialization.
        * **Semantic Action**: A declaration AST node is created by `make_declaration_node($2, NULL, TYPE_INT)` for an integer variable named `$2` (the identifier's string value), with no initial value (`NULL`).
    * `INT_KEYWORD IDENTIFIER ASSIGNMENT_OPERATOR expression { $$ = make_declaration_node($2, $4, TYPE_INT); }`: Integer declaration with initialization.
        * **Semantic Action**: Similar to the above, but the `expression`'s AST node (`$4`) is passed as the initial value.
    * `BOOL_KEYWORD IDENTIFIER { $$ = make_declaration_node($2, NULL, TYPE_BOOL); }`: Boolean declaration without initialization.
    * `BOOL_KEYWORD IDENTIFIER ASSIGNMENT_OPERATOR expression { $$ = make_declaration_node($2, $4, TYPE_BOOL); }`: Boolean declaration with initialization.

* **`assignment`**: Defines how values are assigned to variables.
    * `IDENTIFIER ASSIGNMENT_OPERATOR expression { $$ = make_assign_node($1, $3); }`: An identifier, followed by an assignment operator, and an expression.
        * **Semantic Action**: An assignment AST node is created by `make_assign_node($1, $3)`, taking the identifier's string value (`$1`) and the expression's AST node (`$3`) as arguments.

* **`comparison`**: Defines relational expressions.
    * `expression COMPARISON_OPERATOR expression { $$ = make_binop_node($2, $1, $3); }`: Two expressions separated by a comparison operator.
        * **Semantic Action**: A binary operation AST node is created by `make_binop_node($2, $1, $3)`. The operator (`$2`, a string like "==" or "<") is the first argument, followed by the left-hand side expression (`$1`) and the right-hand side expression (`$3`).

* **`expression`**: Defines arithmetic and literal expressions.
    * `CONSTANT { $$ = make_int_node($1); }`: An integer constant.
        * **Semantic Action**: An integer literal AST node is created by `make_int_node($1)`, using the integer value of the constant (`$1`).
    * `BOOLEAN_LITERAL { $$ = make_bool_node($1); }`: A boolean literal.
        * **Semantic Action**: A boolean literal AST node is created by `make_bool_node($1)`.
    * `IDENTIFIER { $$ = make_var_node($1); }`: An identifier representing a variable.
        * **Semantic Action**: A variable reference AST node is created by `make_var_node($1)`.
    * `expression PLUS expression { $$ = make_binop_node("+", $1, $3); }`: Addition.
        * **Semantic Action**: A binary operation node for addition is created.
    * `expression MINUS expression { $$ = make_binop_node("-", $1, $3); }`: Subtraction.
    * `expression TIMES expression { $$ = make_binop_node("*", $1, $3); }`: Multiplication.
    * `expression DIVIDE expression { $$ = make_binop_node("/", $1, $3); }`: Division.
        * Due to `%left` and the order of rules, `TIMES` and `DIVIDE` have higher precedence than `PLUS` and `MINUS`.
    * `LEFT_PAREN expression RIGHT_PAREN { $$ = $2; }`: Parenthesized expression.
        * **Semantic Action**: The parentheses simply group the expression; the semantic value is merely the inner expression's AST node (`$2`).

---

### Additional C Code Section

```c
void yyerror(const char *s) {
    fprintf(stderr, "Syntax Error: %s at line %d\n", s, yylineno);
    syntax_errors++; // Increment the error counter
}

int main(int argc, char** argv) {
    if (argc > 1) {
        FILE* file = fopen(argv[1], "r");
        if (!file) {
            perror("fopen");
            return 1;
        }
        yyin = file;
    }

    // Enable token printing
    print_tokens = 1;

    // Print the lexical analysis header
    printf("\n-----------------------------LEXICAL ANALYSIS-----------------------\n");

    // Parse the input which will also print tokens as they're scanned
    int parse_result = yyparse();

    // Disable token printing after first pass (in case we need to parse again)
    print_tokens = 0;

    // Check if parsing was successful
    if (syntax_errors > 0) {
        printf("Compilation aborted due to syntax errors.\n");
        return 1;
    }

    // Print the syntax analysis header
    printf("\n--------------------------SYNTAX ANALYSIS---------------------\n");

    // Only proceed if we have a valid AST
    if (root) {
        print_ast(root, 0);

        // Print the semantic analysis header
        printf("\n----------------------SEMANTIC ANALYSIS----------------\n");
        semantic_check(root);
        print_symbol_table();

        // Print the code generation header
        printf("\n----------------------CODE GENERATION----------------\n");
        printf("Generating code...\n");
        generate_code(root, "out.tac");
    } else {
        printf("No valid AST was produced.\n");
        return 1;
    }

    return 0;
}
```

This section, positioned after the second `%%`, contains arbitrary C code that is directly copied into the generated `parser.tab.c` file. This is typically where the `main` function and any auxiliary functions not directly part of the grammar rules are placed.

* **`void yyerror(const char *s)`**:
    * This is the custom error handling function. When `yyparse()` encounters a syntax error, `yyerror()` is called.
    * An error message is printed to `stderr`, indicating the type of syntax error and the line number where it occurred (using `yylineno`).
    * The `syntax_errors` counter is also incremented, which is subsequently used to determine if compilation should proceed.

* **`int main(int argc, char** argv)`**:
    * This is the entry point of the compiler program.
    * **Input File Handling**: A check is performed to see if a filename is provided as a command-line argument. If so, an attempt is made to open the file, and `yyin` (the lexer's input stream) is set to that file. If no file is provided, `yyin` defaults to standard input.
    * **Lexical Analysis Output**: `print_tokens` is set to `1` to enable the printing of tokens during the lexical analysis phase, providing useful debugging information. A header for lexical analysis is then printed.
    * **Parsing**: `int parse_result = yyparse();`
        * This crucial call initiates the parsing process. `yyparse()` reads tokens from `yylex()` and attempts to match them against the grammar rules. It returns `0` on success and a non-zero value on error.
    * **Error Checking**: After parsing, the `syntax_errors` counter is checked. If any syntax errors were found, a message is printed, and execution is terminated, preventing further compilation steps.
    * **AST and Subsequent Phases**:
        * A header for "SYNTAX ANALYSIS" is printed.
        * `if (root)`: A check is performed to see if an AST `root` node was successfully created. If parsing was successful, `root` should point to the complete AST.
        * `print_ast(root, 0);`: This calls a function (presumably defined in `ast.h` or `ast.c`) to print a visual representation of the generated AST, which is invaluable for debugging the parser.
        * **Semantic Analysis**: A header for "SEMANTIC ANALYSIS" is printed, and then `semantic_check(root)` and `print_symbol_table()` are called. These functions, defined in `semantic.h`/`semantic.c`, would perform tasks such as type checking, variable scope resolution, and symbol table population.
        * **Code Generation**: A header for "CODE GENERATION" is printed, and then `generate_code(root, "out.tac")` is called. This function, defined in `codegen.h`/`codegen.c`, would traverse the AST and generate intermediate code (in this case, "three-address code" to "out.tac").
    * If no valid AST was produced (e.g., due to parsing errors that prevented `root` from being set), an appropriate message is printed.
    * **Return Value**: The `main` function returns `0` on successful compilation and `1` on error.

---

# Intermediate Code Representation 

## 1. Overview

The **Intermediate Code Generation (ICG)** phase is a crucial step in the compilation process. It acts as a bridge, transforming the high-level program represented by the Abstract Syntax Tree (AST) into a simplified, machine-independent format.

**Why do we need it?**
* **Abstraction:** It takes complex, hierarchical AST structures and flattens them into a linear sequence of operations.
* **Machine Independence:** The output isn't tied to any specific computer architecture, making it easier to port the compiler to different machines or to generate code for multiple targets.
* **Optimization Ready:** This intermediate form is ideal for applying various compiler optimizations (like removing redundant code or simplifying calculations) before generating the final machine code.

This compiler uses **Three-Address Code (TAC)** as its intermediate representation.

**Three-Address Code (TAC):**
TAC is a simple yet powerful form where each instruction typically has at most three "addresses" or operands: two for the arguments and one for the result. This breaks down complicated operations into basic, atomic steps.

For example, a complex expression like `result = (a + b) * (c - d)` would be broken down into individual TAC instructions using **temporary variables** (`t0`, `t1`, etc.) to store intermediate results:

```
t0 = a + b
t1 = c - d
result = t0 * t1
```

The output of this phase is a sequence of these Three-Address Code instructions, collected in an in-memory array and then written to a specified output file.

---

## 2. Pseudocode: TAC Generator Algorithm

The core of our Intermediate Code Generator involves a recursive traversal of the AST. Different types of AST nodes are handled by specialized functions that emit the corresponding TAC instructions.

### Main Entry Point: `generate_code(root_node, output_filename)`

This function kicks off the code generation process.

```pseudocode
Function generate_code(root_node, output_filename):
    // Initialize counters for TAC instructions and temporary variables
    Reset global tac_index = 0
    Reset global temp_index = 0

    // Start the recursive traversal from the root of the AST
    Call generate_stmt(root_node)

    // Once all TAC is generated, write it to the specified file
    Call emit_TAC_to_file(output_filename)
```

### Statement Generation: `generate_stmt(node)`

This function is responsible for translating various kinds of **statements** into sequences of TAC instructions. It often calls `generate_expr` to handle any expressions found within the statements.

```pseudocode
Function generate_stmt(node):
    If node is null, return

    Switch (node.type):
        Case NODE_STMT_LIST:
            // Process each statement in a block sequentially
            For each statement 's' in node.stmt_list.stmts:
                Call generate_stmt(s) // Recursively generate TAC for each statement

        Case NODE_DECL:
            // If a declaration includes an initial value, generate assignment TAC
            If node.decl.init_value exists:
                result_of_expr = Call generate_expr(node.decl.init_value)
                Emit TAC: "node.decl.var_name = result_of_expr"

        Case NODE_ASSIGN:
            // Generate TAC for variable assignment
            result_of_expr = Call generate_expr(node.assign.expr)
            Emit TAC: "node.assign.var_name = result_of_expr"

        Case NODE_PRINT:
            // Generate TAC for printing an expression's value
            result_of_expr = Call generate_expr(node.print_expr)
            Emit TAC: "print result_of_expr"

        Case NODE_IF:
            // Generate unique labels to control flow for if-else statements
            label_if = new_label()     // For the 'then' block
            label_else = new_label()   // For the 'else' block (or after 'if' if no else)
            label_end = new_label()    // For the point after the entire if-else construct

            // Evaluate the if condition
            cond_result = Call generate_expr(node.if_stmt.condition)

            // Emit TAC for the conditional jump
            Emit TAC: "if cond_result goto label_if"

            // If the condition is false, jump to the 'else' block
            Emit TAC: "goto label_else"

            // Mark the beginning of the 'then' block
            Emit TAC: "label label_if"
            Call generate_stmt(node.if_stmt.if_body) // Recursively generate TAC for the 'then' block

            // After the 'then' block, jump to the end of the if-else to skip 'else'
            Emit TAC: "goto label_end"

            // Mark the beginning of the 'else' block
            Emit TAC: "label label_else"
            If node.if_stmt.else_body exists:
                Call generate_stmt(node.if_stmt.else_body) // Recursively generate TAC for the 'else' block

            // Mark the end of the entire if-else construct
            Emit TAC: "label label_end"

        Default:
            // Handle any unhandled or unexpected statement types
            Do nothing or report error
    End Switch
```

### Expression Generation: `generate_expr(node)`

This function handles the translation of **expressions** into TAC. It returns the name of the variable (either a program variable or a temporary) where the final result of the expression is stored.

```pseudocode
Function generate_expr(node):
    If node is null, return "?" (error placeholder)

    Switch (node.type):
        Case NODE_INT:
            // Return the string representation of an integer literal (e.g., "5")
            Return string_of(node.int_value)

        Case NODE_BOOL:
            // Return the string representation of a boolean literal (e.g., "0" or "1")
            Return string_of(node.int_value)

        Case NODE_VAR:
            // Return the name of the variable (e.g., "x")
            Return node.var_name

        Case NODE_BINOP:
            // Recursively generate TAC for left and right operands
            left_result = Call generate_expr(node.binop.left)
            right_result = Call generate_expr(node.binop.right)

            // Get a new temporary variable to store the result of this operation
            temp_var = Call new_temp()

            // Emit TAC for the binary operation
            Emit TAC: "temp_var = left_result node.binop.op right_result"

            // The temporary variable holds the result of this expression
            Return temp_var

        Default:
            // Handle any unhandled or unexpected expression types
            Return "?" (error placeholder)
    End Switch
```

### Helper Functions:

* **`new_temp()`**: Generates and returns a unique name for a temporary variable (e.g., `t0`, `t1`, `t2`). These are crucial for breaking down complex expressions into single-operation TAC instructions.
* **`new_label()`**: Generates and returns a unique label name (e.g., `L0`, `L1`, `L2`). These are used for control flow instructions like `goto` and `ifgoto`.
* **`emit_TAC_to_file(filename)`**: This utility function is responsible for iterating through the entire list of generated TAC instructions and writing them to the specified output file in a human-readable format.

---

## 3. Sample Output

Let's look at an example C-like program and the Three-Address Code (3AC) that would be generated by this phase.

**Sample Program (C-like Source Code):**

```c
int x = 5;
bool flag = true;
if (x > 5) {
    print x;
    x = x + 1;
} else {
    print 0;
    flag = false;
}
print flag;
```

**Resulting Three-Address Code (3AC):**

```
x = 5
flag = 1
t0 = x > 5
if t0 goto L0
goto L1
L0:
print x
t1 = x + 1
x = t1
goto L2
L1:
print 0
flag = 0
L2:
print flag
```
